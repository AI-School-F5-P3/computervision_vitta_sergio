{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CONFIGURACIÓN DEL DATASET ===\n",
      "path: 0 imágenes en train_data/dataset/logos\n",
      "train: 0 imágenes en train_data/dataset/logos/train/images\n",
      "val: 0 imágenes en train_data/dataset/logos/valid/images\n",
      "test: 0 imágenes en train_data/dataset/logos/test/images\n",
      "Clases: ['adidas', 'apple', 'ericsson', 'nike', 'reebok', 'samsung', 'sony']\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_data/dataset/logos/data.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Guardar la configuración\u001b[39;00m\n\u001b[0;32m     37\u001b[0m config_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_data/dataset/logos/data.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     39\u001b[0m     yaml\u001b[38;5;241m.\u001b[39mdump(data_config, file)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Inicializar modelo\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vitta\\Desktop\\F5_Bootcamp\\computervision_vitta_sergio\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_data/dataset/logos/data.yaml'"
     ]
    }
   ],
   "source": [
    "#Instalamos las dependencias necesarias\n",
    "#!pip install ultralytics roboflow\n",
    "#!pip install wandb  # Para seguimiento de entrenamiento\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Función para formatear tiempo\n",
    "def format_time(seconds):\n",
    "    return time.strftime('%H:%M:%S', time.gmtime(seconds))\n",
    "\n",
    "\n",
    "# Ruta al directorio de tu dataset\n",
    "DATASET_PATH = 'train_data/dataset/logos'\n",
    "\n",
    "# Crear configuración del dataset\n",
    "data_config = {\n",
    "    'path': DATASET_PATH,\n",
    "    'train': 'train_data/dataset/logos/train/images',\n",
    "    'val': 'train_data/dataset/logos/valid/images',\n",
    "    'test': 'train_data/dataset/logos/test/images',\n",
    "    'names': ['adidas', 'apple', 'ericsson', 'nike', 'reebok', 'samsung', 'sony']\n",
    "}\n",
    "\n",
    "# Imprimir información del dataset\n",
    "print(\"\\n=== CONFIGURACIÓN DEL DATASET ===\")\n",
    "for key, path in data_config.items():\n",
    "    if key != 'names':\n",
    "        n_images = len(os.listdir(path)) if os.path.exists(path) else 0\n",
    "        print(f\"{key}: {n_images} imágenes en {path}\")\n",
    "print(f\"Clases: {data_config['names']}\\n\")\n",
    "\n",
    "\n",
    "# Guardar la configuración\n",
    "config_path = 'train_data/dataset/logos/data.yaml'\n",
    "with open(config_path, 'w') as file:\n",
    "    yaml.dump(data_config, file)\n",
    "\n",
    "# Inicializar modelo\n",
    "modelo = YOLO('yolov8n.pt')\n",
    "\n",
    "# Configurar callbacks para métricas\n",
    "def on_train_epoch_end(trainer):\n",
    "    epoch = trainer.epoch\n",
    "    metrics = trainer.metrics\n",
    "    print(f\"\\nEpoch {epoch + 1}:\")\n",
    "    print(f\"mAP50: {metrics['metrics/mAP50(B)']:.3f}\")\n",
    "    print(f\"Precision: {metrics['metrics/precision(B)']:.3f}\")\n",
    "    print(f\"Recall: {metrics['metrics/recall(B)']:.3f}\")\n",
    "    print(f\"Tiempo transcurrido: {format_time(time.time() - start_time)}\")\n",
    "\n",
    "# Configurar hiperparámetros\n",
    "hiperparametros = {\n",
    "    'epochs': 150,\n",
    "    'batch': 8,\n",
    "    'imgsz': 640,\n",
    "    'patience': 30,\n",
    "    'optimizer': 'Adam',\n",
    "    'lr0': 0.001,\n",
    "    'lrf': 0.01,\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3,\n",
    "    'cos_lr': True,\n",
    "    'close_mosaic': 10,\n",
    "    'label_smoothing': 0.1,\n",
    "    'device': 'cpu',\n",
    "    'augment': True,\n",
    "    'workers': 1,\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"\\nHiperparámetros:\")\n",
    "for key, value in hiperparametros.items():\n",
    "    if key != 'callbacks':\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "resultados = modelo.train(\n",
    "    data=config_path,\n",
    "    **hiperparametros\n",
    ")\n",
    "\n",
    "# Tiempo total de entrenamiento\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\nTiempo total de entrenamiento: {format_time(training_time)}\")\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"\\n=== EVALUACIÓN DEL MODELO ===\")\n",
    "metricas = modelo.val()\n",
    "\n",
    "# Resumen final\n",
    "print(\"\\n=== RESUMEN FINAL ===\")\n",
    "print(f\"Mejor mAP50: {max(resultados.results_dict['metrics/mAP50(B)']):.3f}\")\n",
    "print(f\"Mejor Precision: {max(resultados.results_dict['metrics/precision(B)']):.3f}\")\n",
    "print(f\"Mejor Recall: {max(resultados.results_dict['metrics/recall(B)']):.3f}\")\n",
    "\n",
    "# Exportar el modelo\n",
    "print(\"\\n=== EXPORTANDO MODELO ===\")\n",
    "modelo.export(format='onnx')\n",
    "modelo.export(format='torchscript')\n",
    "print(\"Exportación completada!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
